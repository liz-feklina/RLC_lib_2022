{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict as dd\n",
    "from copy import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "headers = {'User-Agent': ua.random}\n",
    "#print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from numpy.random import choice\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# форма поискового запроса к корпусу\n",
    "req1 = 'http://web-corpora.net/RLC/search/?exact_word=&wordform%5B%5D=&lex%5B%5D=&grammar%5B%5D=&errors%5B%5D='\n",
    "req2 = '&from%5B%5D=1&to%5B%5D=1&wordform%5B%5D=&lex%5B%5D=&grammar%5B%5D=&errors%5B%5D=&lex_search=Search&date1=&date2=&gender=any&mode=any&background=any&language%5B%5D=fin&format=full&per_page=50&expand=%2B-1&page='\n",
    "\n",
    "# откуда брать информацию об ошибке\n",
    "search = 'http://web-corpora.net/RLC/document-annotations/search?document='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, создающая запрос по типу ошибки (для нескольких ищет вхождения с хотя бы одной из списка)\n",
    "def create_req(error):\n",
    "    if type(error) == str:\n",
    "        return req1 + error + req2\n",
    "    elif type(error) == list:\n",
    "        return req1 +'('+'%7C'.join(error) + ')' + req2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Орфографические"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Замена буквы\n",
    "2. Убирание буквы из кластера согласных\n",
    "3. Мягкий знак\n",
    "4. Дефисное/пробельное/слитное написание\n",
    "5. Редукция и гиперкоррекция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Замена буквы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Данные по заменам вычислены в RLC_crawlers.ipynb)\n",
    "\n",
    "with open('Counter_pairs.json', 'r', encoding='utf-8') as f:\n",
    "    pairs = json.load(f)\n",
    "\n",
    "repl_dict = dict()\n",
    "for pair in pairs:\n",
    "    if pair[0][0] == pair[0][1]:\n",
    "        continue\n",
    "    if pair[0][0] not in repl_dict:\n",
    "        repl_dict[pair[0][0]] = []\n",
    "    repl_dict[pair[0][0]].append([pair[0][1], pair[1]])\n",
    "\n",
    "all_letters = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'о': [['а', 131], ['и', 6], ['у', 6], ['е', 5], ['ы', 3]],\n",
       " 'ы': [['и', 122], ['о', 6], ['е', 4]],\n",
       " 'и': [['е', 113], ['ы', 32], ['й', 31], ['о', 6], ['у', 4]],\n",
       " 'а': [['о', 88], ['и', 16], ['е', 13], ['я', 11]],\n",
       " 'е': [['и', 72], ['о', 23], ['э', 14], ['я', 9], ['а', 3], ['й', 3]],\n",
       " 'щ': [['ш', 45], ['ж', 3]],\n",
       " 'з': [['с', 42]],\n",
       " 'с': [['з', 38], ['ц', 5]],\n",
       " 'э': [['е', 33]],\n",
       " 'й': [['и', 26]],\n",
       " 'я': [['е', 19], ['а', 18], ['и', 14]],\n",
       " 'д': [['т', 13]],\n",
       " 'ъ': [['ь', 9]],\n",
       " 'ж': [['ш', 8], ['з', 3]],\n",
       " 'ш': [['щ', 8], ['с', 6], ['ж', 5]],\n",
       " 'т': [['д', 8], ['ц', 3]],\n",
       " 'ч': [['ш', 7], ['щ', 4]],\n",
       " 'ь': [['ъ', 6], ['и', 5]],\n",
       " 'г': [['в', 6], ['к', 4]],\n",
       " 'л': [['д', 6]],\n",
       " 'ц': [['ч', 6]],\n",
       " 'к': [['г', 5]],\n",
       " 'р': [['п', 4]],\n",
       " 'у': [['о', 4], ['ы', 3]],\n",
       " 'в': [['б', 3]],\n",
       " 'н': [['х', 3]],\n",
       " 'б': [['п', 3]],\n",
       " 'ю': [['и', 2]]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, subset=all_letters, prob=0.2):\n",
    "    new_word = ''\n",
    "    \n",
    "    for l in word:\n",
    "        if l in repl_dict and l in subset:\n",
    "            r = choice([True, False], 1, p=[prob, 1 - prob]) # выбираем, совершать ли замену\n",
    "            if r:\n",
    "                letters = [l for l, n in repl_dict[l]] # список возможных букв\n",
    "                l_sum = sum(n for _, n in repl_dict[l])\n",
    "                distr = [n/l_sum for l, n in repl_dict[l]] # распределение вероятностей, на некоторые заменяют чаще, на некоторые реже\n",
    "                new_letter = choice(letters, 1, p=distr)[0]\n",
    "                new_word += new_letter\n",
    "            else:\n",
    "                new_word += l\n",
    "        else:\n",
    "            new_word += l\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'толебизор'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_letter('телевизор')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'быходные'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_letter('выходные')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Убирание буквы из кластера согласных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем кластеры регуляркой, про каждый понимаем его длину и с некоторой вероятностью удаляем какую-то из букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_pattern = '[бвгджзйклмнпрстфхцчшщ]{2,}'\n",
    "cl_distr = [70/(70+42+63), 42/(70+42+63), 63/(70+42+63)]\n",
    "cl_distr_2 = [70/(70+63), 63/(70+63)]\n",
    "\n",
    "def reduce_cluster(word, prob=0.5):\n",
    "    new_word = word\n",
    "    for m in re.finditer(cl_pattern, word):\n",
    "        r = choice([True, False], 1, p=[prob, 1 - prob])\n",
    "        if r:\n",
    "            if m.end(0) - m.start(0) > 2:\n",
    "                c_len = m.end(0) - m.start(0) - 2\n",
    "                new_distr = [cl_distr[0]]+[cl_distr[1]/c_len]*c_len+[cl_distr[2]]\n",
    "                l_i = choice(list(range(0, m.end(0) - m.start(0))), 1, p=new_distr)[0]\n",
    "            else:\n",
    "                l_i = choice([0, 1], 1, p=cl_distr_2)[0]\n",
    "            new_word = new_word[:m.start(0)+l_i] + ' ' + new_word[m.start(0)+l_i+1:]\n",
    "    return new_word.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'приветстовать'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_cluster('приветствовать')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'детства'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_cluster('детства')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Мягкий знак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_b_pattern = 'ь'\n",
    "\n",
    "def del_b(word, prob=0.5):\n",
    "    new_word = word\n",
    "    for m in re.finditer(del_b_pattern, word):\n",
    "        r = choice([True, False], 1, p=[prob, 1 - prob])\n",
    "        if r:\n",
    "            new_word = new_word[:m.start(0)] + ' ' + new_word[m.start(0)+1:]\n",
    "    return new_word.replace(' ', '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'уменшительност'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_b('уменьшительность')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_b_pattern = '[бвгджзйклмнпрстфхцчшщ]{2}[еиюяь]'\n",
    "\n",
    "def add_b(word, prob=0.5):\n",
    "    s = 0\n",
    "    bs_parts = []\n",
    "    new_word = word\n",
    "    for m in re.finditer(add_b_pattern, word):\n",
    "        r = choice([True, False], 1, p=[prob, 1 - prob])\n",
    "        if r:\n",
    "            new_word = new_word[:m.start(0)+s+1] + 'ь' + new_word[m.start(0)+s+1:]\n",
    "            s += 1\n",
    "    if new_word[-1] not in 'аеиоуюяыэьйъ':\n",
    "        r = choice([True, False], 1, p=[prob, 1 - prob])\n",
    "        if r:\n",
    "            new_word += 'ь'\n",
    "    \n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'приветьривать'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_b('приветриват')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Дефисное/пробельное/слитное написание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_s_pattern = '[\\- ]'\n",
    "hyph_distr = [21/(136+21), 136/(136+21)]\n",
    "\n",
    "def hyphen_space(word, prob = 0.5):\n",
    "    new_word = word\n",
    "    if '-' in word:\n",
    "        distr = [prob*hyph_distr[0], 1 - prob, prob*hyph_distr[1]]\n",
    "        r = choice(['', '-', ' '], 1, p=distr)[0]\n",
    "        new_word = new_word.replace('-', r)   \n",
    "    else:\n",
    "        r = choice(['', '-', ' '], 1, p=[1/3, 1/3, 1/3])[0]\n",
    "        new_word = new_word.replace(' ', r)    \n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'по английски'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyphen_space('по-английски')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Редукция и гиперкоррекция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aot_json(word):\n",
    "    url = 'http://63.250.59.227:8080/?'\n",
    "    data = {'action': 'morph',\n",
    "            'langua': 'Russian',\n",
    "            'query': word,\n",
    "            'withparadigms': '1',}\n",
    "    html_content = requests.get(url, data).text\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordlist(word):\n",
    "    a = get_aot_json(word)\n",
    "    b = json.loads(a)\n",
    "    forms_list = []\n",
    "    for paradigm in b[0]['paradigm']:\n",
    "        for formsGroup in paradigm['formsGroups']:\n",
    "            for form in formsGroup['forms']:\n",
    "                forms_list.append(form['f'].lower())\n",
    "    return forms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_dict = dict()\n",
    "\n",
    "red_dict['е'] = 'и'\n",
    "red_dict['о'] = 'а'\n",
    "red_dict['я'] = 'и'\n",
    "red_dict['э'] = 'ы'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reduction(word, prob = 0.5):\n",
    "    wordlist = get_wordlist(word)\n",
    "    wordlist_unaccent = [word.replace(\"'\", '') for word in wordlist]\n",
    "    try:\n",
    "        in_list = wordlist_unaccent.index(word)\n",
    "        my_word = wordlist[in_list]\n",
    "    except:\n",
    "        print('Слово не нашлось в словаре!')\n",
    "        return word\n",
    "    if \"'\" not in my_word:\n",
    "        print('Слово не нашлось в словаре!')\n",
    "        return word\n",
    "    for i in range(len(word)):\n",
    "        if my_word[i] in 'еояэ' and my_word[i+1] != \"'\":\n",
    "            r = choice([True, False], 1, p=[prob, 1 - prob])[0]\n",
    "            if r:\n",
    "                my_word = my_word[:i] + red_dict[my_word[i]] + my_word[i+1:]\n",
    "    return my_word.replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'адияло'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction('одеяло', prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_red_dict = dict()\n",
    "\n",
    "un_red_dict['а'] = 'о'\n",
    "un_red_dict['и'] = 'е'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un_reduction(word, prob = 0.5):\n",
    "    wordlist = get_wordlist(word)\n",
    "    wordlist_unaccent = [word.replace(\"'\", '') for word in wordlist]\n",
    "    try:\n",
    "        in_list = wordlist_unaccent.index(word)\n",
    "        my_word = wordlist[in_list]\n",
    "    except:\n",
    "        print('Слово не нашлось в словаре!')\n",
    "        return word\n",
    "    if \"'\" not in my_word:\n",
    "        print('Слово не нашлось в словаре!')\n",
    "        return word\n",
    "    for i in range(len(word)):\n",
    "        if my_word[i] in 'иа' and my_word[i+1] != \"'\":\n",
    "            r = choice([True, False], 1, p=[prob, 1 - prob])[0]\n",
    "            if r:\n",
    "                my_word = my_word[:i] + un_red_dict[my_word[i]] + my_word[i+1:]\n",
    "    return my_word.replace(\"'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'овтострада'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_reduction('автострада', prob=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Морфологические"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Поиск похожего (с зафиксированным префиксом)\n",
    "2. Изменение/удаление префикса\n",
    "3. Изменение окончания (парадигмы)\n",
    "4. Чередующиеся основы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Поиск похожего (изменение/удаление префикса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefs = 'в- (во-), взо-, вне-, внутри-, возо-, вы-, до-, еже-, за-, зако-, изо-, испод-, к-, кое-, ку-, меж- (междо-, между-), на-, над- (надо-), наи-, не-, недо-, ни-, низо-, о-, об- (обо-), около-, от- (ото-), па-, пере-, по-, под- (подо-), поза-, после-, пра-, пред- (преди-, предо-), про-, противо-, разо-, с- (со-), сверх-, среди-, су-, тре-, у-, пре-, при-.'[:-1].replace('-', '').replace(' (', ', ').replace(')', '').split(', ')\n",
    "prefs.extend('без-/бес-, вз-/вс-, воз-/вос-, из-/ис-, низ-/нис-, обез-/обес-, раз-/рас-, роз-/рос-, через-/черес- (чрез-/чрес-)'.replace('-', '').replace('/', ', ').replace(' (', ', ').replace(')', '').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_verbs_df = pd.read_csv('freq_verbs.csv', encoding='utf-8')\n",
    "freq_verbs_list = freq_verbs_df['Лемма'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pref(word, prefs):\n",
    "    max_pref = ''\n",
    "    len_pref = 0\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        if word[:(i+1)] in prefs:\n",
    "            max_pref = word[:(i+1)]\n",
    "            len_pref = i+1\n",
    "    \n",
    "    return max_pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_pref(cor_verb):\n",
    "\n",
    "    cor_pref = find_pref(cor_verb, prefs)\n",
    "    stem = morph.parse(cor_verb)[0].normal_form[len(cor_pref):]\n",
    "\n",
    "    fr_verb = None\n",
    "    for verb in freq_verbs_list:\n",
    "        if verb.endswith(stem):\n",
    "            fr_verb = verb\n",
    "            break\n",
    "    if fr_verb:\n",
    "        form = fr_verb[:-len(stem)]+cor_verb[len(cor_pref):]\n",
    "        return form\n",
    "    else:\n",
    "        form = None\n",
    "        print('Не нашлось :(')\n",
    "        return cor_verb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сделать'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modify_pref('недоделать')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Поиск похожего (с зафиксированным префиксом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('russian.txt', 'r') as f:\n",
    "    words = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simil_pref(my_word):\n",
    "    pre = my_word[:2]\n",
    "    pre_words = [word for word in words if word.startswith(pre)]\n",
    "    pre_dist = [(word, nltk.edit_distance(word, my_word)) for word in pre_words]\n",
    "    \n",
    "    for word in sorted(pre_dist, key=lambda x: x[1])[1:]:\n",
    "        if morph.parse(my_word)[0].tag == morph.parse(word[0])[0].tag:\n",
    "            return word[0]\n",
    "    print('Ничего не нашлось :(')\n",
    "    return my_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'собачка'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simil_pref('собака')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Изменение окончания (парадигмы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_dict = dict()\n",
    "flex_dict['ед'] = dict()\n",
    "flex_dict['мн'] = dict()\n",
    "flex_dict['ед']['им'] = ['а', 'я', 'о', 'е', '', 'ь', 'й']\n",
    "flex_dict['ед']['рд'] = ['и', 'ы', 'а', 'я']\n",
    "flex_dict['ед']['дт'] = ['и', 'е', 'у', 'ю']\n",
    "flex_dict['ед']['вн'] = ['у', 'ю', 'ь', '', 'й', 'а', 'я']\n",
    "flex_dict['ед']['тв'] = ['ой', 'ей', 'ью', 'ом', 'ем']\n",
    "flex_dict['ед']['пр'] = ['е', 'и']\n",
    "\n",
    "flex_dict['мн']['им'] = ['а', 'я', 'ы', 'и']\n",
    "flex_dict['мн']['рд'] = ['', 'ь', 'ей', 'ов', 'ев', 'й']\n",
    "flex_dict['мн']['дт'] = ['ам', 'ям']\n",
    "flex_dict['мн']['вн'] = ['й', 'ев', 'ь', 'ов', 'ей', 'а', 'я', 'ы', 'и']\n",
    "flex_dict['мн']['тв'] = ['ами', 'ями']\n",
    "flex_dict['мн']['пр'] = ['ах', 'ях']\n",
    "\n",
    "vowels = ['а','е','и','о','у','ю','я','ы','э']\n",
    "hard_cons = ['ц', 'ш', 'ж', 'ч', 'щ', 'к', 'г']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flex(word, flexes):\n",
    "    max_flex = ''\n",
    "    len_flex = 0\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        if word[-(i+1):] in flexes:\n",
    "            max_flex = word[-(i+1):]\n",
    "            len_flex = i+1\n",
    "    \n",
    "    return max_flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_paradigm(word, case=None, number=None):\n",
    "    \n",
    "    if not case and not number:\n",
    "        ana = morph.parse(word)[0]\n",
    "        case = morph.lat2cyr(ana.tag.case)\n",
    "        number = morph.lat2cyr(ana.tag.number)\n",
    "    \n",
    "    elif not case:\n",
    "        anas = morph.parse(word)\n",
    "        for ana in anas:\n",
    "            if morph.lat2cyr(ana.tag.number) == number:\n",
    "                case = morph.lat2cyr(ana.tag.case)\n",
    "                break\n",
    "    \n",
    "    elif not number:\n",
    "        anas = morph.parse(word)\n",
    "        for ana in anas:\n",
    "            if morph.lat2cyr(ana.tag.case) == case:\n",
    "                number = morph.lat2cyr(ana.tag.number)\n",
    "                break\n",
    "            \n",
    "    print(ana)\n",
    "    flexes = copy(flex_dict[number][case])\n",
    "    \n",
    "    flex = find_flex(word, flexes)\n",
    "    \n",
    "    stem = word[:-len(flex)]\n",
    "    if stem[-1] in vowels:\n",
    "        try:\n",
    "            flexes.remove('ь')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        try:\n",
    "            flexes.remove('')\n",
    "        except ValueError:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            flexes.remove('й')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        if stem[-1] in hard_cons:\n",
    "            try:\n",
    "                flexes.remove('ю')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            try:\n",
    "                flexes.remove('я')\n",
    "            except ValueError:\n",
    "                pass\n",
    "            try:\n",
    "                flexes.remove('ю')\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "    flexes.remove(flex)\n",
    "    new_flex = random.choice(flexes)\n",
    "    new_word = stem+new_flex\n",
    "    \n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse(word='родители', tag=OpencorporaTag('NOUN,anim,masc plur,nomn'), normal_form='родитель', score=1.0, methods_stack=((DictionaryAnalyzer(), 'родители', 122, 6),))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'родителы'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_paradigm('родители', case=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Чередующиеся основы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_flexes = copy(flex_dict['ед']['им'])\n",
    "alt_pattern = r'([цшжчщкг])я'\n",
    "\n",
    "def altern(word):\n",
    "    ana = morph.parse(word)[0]\n",
    "    pos = ana.tag.POS\n",
    "    if pos == 'NOUN':\n",
    "        \n",
    "        case = morph.lat2cyr(ana.tag.case)\n",
    "        number = morph.lat2cyr(ana.tag.number)\n",
    "        flexes = copy(flex_dict[number][case])\n",
    "        \n",
    "        flex = find_flex(word, flexes)\n",
    "        \n",
    "        lemma = ana.normal_form\n",
    "        lemma_flex = find_flex(lemma, lemma_flexes)\n",
    "        \n",
    "        if len(lemma_flex) == 0:\n",
    "            new_word = lemma + flex\n",
    "        else:\n",
    "            new_word = lemma[:-len(lemma_flex)] + flex\n",
    "        \n",
    "        new_word = re.sub(alt_pattern, r'\\1а', new_word)\n",
    "        return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'прогулк'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altern('прогулок')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
